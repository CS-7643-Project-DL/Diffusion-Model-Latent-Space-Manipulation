{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m venv mmlabs\n",
    "pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install mmcv==2.2.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.2/index.html\n",
    "```\n",
    "https://pytorch.org/get-started/previous-versions/\n",
    "https://mmcv.readthedocs.io/en/latest/get_started/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_labels = {\n",
    "    'airplane':5,\n",
    "    'cat':17,\n",
    "    'dog':18,\n",
    "    'elephant':22,\n",
    "    'sheep':20,\n",
    "    'horse':19,\n",
    "    'bus':6,\n",
    "    'motorcycle':4,\n",
    "    'car':3,\n",
    "}\n",
    "\n",
    "scene_labels = {\n",
    "    'Cloud':[106], # cloud\n",
    "    'Runway':[149, 157], # road, sky-other\n",
    "    \n",
    "    'Beach':[154, 155], # sand, sea\n",
    "    'Desert':[156, 135], # sand, mountain\n",
    "    'Forest':[169, 124], # tree, grass\n",
    "    \n",
    "    'City':[158, 96, 140], # skyscraper, building-other, pavement\n",
    "    'Highway':[149], # road\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as u\n",
    "import importlib\n",
    "importlib.reload(u)\n",
    "from utils import categories, categories_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments1_dir = 'data/experiments1/'  # Aggregated Attention\n",
    "experiments2_dir = 'data/experiments2/'  # Scene-Based\n",
    "sd_baseline_dir = 'data/sd_baseline/'\n",
    "importlib.reload(u)\n",
    "\n",
    "resized_imgs, img_names = u.load_original_images('./data/original_resized')\n",
    "imgs1 = u.load_experiment_images(experiments1_dir, to_list=True)  # Aggregated Attention\n",
    "imgs2 = u.load_experiment_images(experiments2_dir,to_list=True)  # Scene-Based\n",
    "sd_base = u.load_experiment_images(sd_baseline_dir,to_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import MMSegInferencer\n",
    "model = 'pspnet_r101-d8_4xb4-320k_coco-stuff164k-512x512'\n",
    "inferencer = MMSegInferencer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = 'data/original/Airplane'\n",
    "# create masks for all original images\n",
    "masks={}\n",
    "vis = {}\n",
    "for category in categories:\n",
    "    input_dir = f'data/original_resized/{category}'\n",
    "    results = inferencer(resized_imgs[category], return_vis=True)\n",
    "    masks[category] = results['predictions']\n",
    "    vis[category] = results['visualization']\n",
    "u.save_imgs(masks, basedir='./data/masks', img_names=img_names, original=True)\n",
    "u.save_imgs(vis, basedir='./data/masks/vis', img_names=img_names, original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sd_base\n",
    "\n",
    "masks={}\n",
    "vis = {}\n",
    "for category in categories:\n",
    "    masks[category] = {}\n",
    "    vis[category] = {}\n",
    "    for scene in categories_scenes[category]:\n",
    "        input_dir = f'data/original_resized/{category}/{scene}'\n",
    "        results = inferencer(imgs[category][scene], return_vis=True)\n",
    "        masks[category][scene] = results['predictions']\n",
    "        vis[category][scene] = results['visualization']\n",
    "u.save_imgs(masks, basedir='./data/masks_sd', img_names=img_names, original=False)\n",
    "u.save_imgs(vis, basedir='./data/masks_sd/vis', img_names=img_names, original=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "classes = {}\n",
    "for category in categories:\n",
    "    potential_classes = np.unique(masks[category])\n",
    "    for img in masks[category]:\n",
    "        # get classes of img\n",
    "        img_class = np.unique(img)\n",
    "        # if any of potential classes not in classes, drop it\n",
    "        for p in potential_classes:\n",
    "            if p not in img_class:\n",
    "                potential_classes = potential_classes[potential_classes != p]\n",
    "    classes[category] = potential_classes\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "coco = COCO('/home/mashalimay/DL_project/Diffusion-Model-Latent-Space-Manipulation/stuff_val2017.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images(cat_ids, num_images=5):\n",
    "    # Get all images containing any of the category IDs\n",
    "    img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "    # Filter to ensure all categories are present in each image\n",
    "    filtered_img_ids = []\n",
    "    for img_id in img_ids:\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids, iscrowd=None)\n",
    "        annotations = coco.loadAnns(ann_ids)\n",
    "        # Check if all category IDs are present in the annotations\n",
    "        if len(cat_ids) == 1:\n",
    "            if any(ann['category_id'] == cat_ids[0] for ann in annotations):\n",
    "                filtered_img_ids.append(img_id)\n",
    "        else:\n",
    "            if all(any(ann['category_id'] == cat_id for ann in annotations) for cat_id in cat_ids):\n",
    "                filtered_img_ids.append(img_id)\n",
    "        if len(filtered_img_ids) >= num_images:\n",
    "            break\n",
    "\n",
    "    # Fetch the images\n",
    "    images = []\n",
    "    for img_id in filtered_img_ids:\n",
    "        img = coco.loadImgs(img_id)[0]\n",
    "        response = requests.get(img['coco_url'])\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        numpy_image = np.array(image)\n",
    "        images.append(numpy_image)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching images for Cloud\n",
      "Fetching images for Runway\n",
      "Fetching images for Beach\n",
      "Fetching images for Forest\n",
      "Fetching images for Desert\n",
      "Fetching images for City\n",
      "Fetching images for Highway\n"
     ]
    }
   ],
   "source": [
    "gt_images = {}\n",
    "for category, scenes in categories_scenes.items():\n",
    "    gt_images[category] = {}\n",
    "    for scene in scenes:\n",
    "        print(f\"Fetching images for {scene}\")\n",
    "        gt_images[category][scene] = fetch_images(scene_labels[scene], num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(u)\n",
    "resized_gt = u.standardize_sizes(gt_images, (512, 512), original=False)\n",
    "\n",
    "u.save_imgs(resized_gt, basedir='./data/gt', img_names=img_names, original=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
